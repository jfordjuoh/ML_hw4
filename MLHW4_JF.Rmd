---
title: "MLHW4_JF"
date: February 11, 2022
output: word_document
---

```{r, echo = FALSE}
library(tidyverse)
library(Amelia)
library(caret)
library(stats)
library(cluster)
library(factoextra)
library(dplyr)
library(readxl)
library(haven)
library(knitr)
library(broom)
```


Q's for sneha:
Qoes gpaq8totmin and gpaq11days have to be a factor? based on the question asked, I believe this is a continuous variable.

FINISH Q3

# Part I Setup: Data Cleaning, Iniital Linear Regression, and Data Partitioning,   
```{r}
# First Task: Perform basic data cleaning. Note which features are continuous, which are categorical and ensure they are being stored that way in your R dataset (That is, if categorical variables have been read-in as continuous variables, convert them to factors)

class4 = read_csv("class4_p1.csv") %>%
    janitor::clean_names() %>%
    rename(observation = x1) %>% #all the variables are cont so we have to convert them all to factors/provide levels except for healthy days (outcome) because we are doing a linear reg 
    mutate(chronic1 = as.factor(chronic1),
           chronic3 = as.factor(chronic3),
           chronic4 = as.factor(chronic4),
           tobacco1 = as.factor(tobacco1), 
           alcohol1 = as.factor(alcohol1),
           habits5 = as.factor(habits5), 
           habits7 = as.factor(habits7),
           agegroup = as.factor(agegroup),
           dem3 = as.factor(dem3),
           dem4 = as.factor(dem4),
           dem8 = as.factor(dem8),
           povertygroup = as.factor(povertygroup)
           ) %>% 
      drop_na()  #dropping all the missing data. The observations don't start at 1 anymore bc it dropped some people

summary(class4)

missmap(class4, main = "Missing values vs observed")
```


```{r}
# First Task part2: Constructing my linear regression 
model1 = lm(healthydays ~ gpaq8totmin + gpaq11days + bmi, data = class4)
summary(model1)
confint(model1)

model2 = lm(healthydays ~ gpaq8totmin + gpaq11days + bmi + povertygroup + agegroup, data = class4)
summary(model2)
confint(model2)
```


```{r}
# Second Task: Partition data into training and testing (use a 70/30 split)  

#Note to self: First I need to find the correlated predictors and remove them using the cor function and then the find correlation function. Set my cutoff to 0.9.
class4_num = class4 %>% 
  select(where(is.numeric)) #only selected observations,bmi, gpaq8,gpaq11,and healthydays

correlations_class4 <- cor(class4_num, use = "complete.obs")
highcorrelations <- findCorrelation(correlations_class4, cutoff = 0.9) #high.correlations was empty so the data isn't correlated so the following dataset shouldn't have any variables.
class4_lowcorr = class4_num[,-highcorrelations]

#NTS: Now I need to center and scale my data using preprocess and then predict. I'll then set my seed to prevent constant randomization and drop the observation variable.

preprocess = preProcess(class4_num, method = c("center", "scale"))
#Output pre-processed values
transformed_vals <- predict(preprocess, class4_num)

set.seed(1000)
class4$observation <- NULL #copied from JS code

train.index <- createDataPartition(class4$healthydays, p = 0.7, list = FALSE)

class4_train <- class4[train.index,]
class4_test <- class4[-train.index,]

```


## Part I: Implementing a Simple Prediction Pipeline
#Question 1 and 2
```{r}
#Q1 Task: Fit two prediction  models using different subsets of the features in the training data. Features can overlap in the two models, but the feature sets should not be exactly the same across models. Clearly state which features were used in the two models.

#Q2 Task: Apply both models within the test data and determine which model is the preferred prediction model using the appropriate evaluation metric(s).

#NTS: If this was a logistic regression I would use a confusion matrix but since this is a linear regression I am using postResample.

#NTS: First I'm tuning my hyperparameter using cross validation (through the train control function.) and doing a 3-fold cross-validation.
control.settings <- trainControl(method = "cv", number = 3)

#Now I'm running my train function
set.seed(1000)
model1_again <- train(healthydays ~ gpaq8totmin + gpaq11days + bmi, data = class4, method = "glm", family = "gaussian", trControl = control.settings)

model1_pred <- predict(model1_again, class4_test)

model1_again

postResample(pred = model1_pred, obs = class4_test$healthydays)


model2_again <- train(healthydays ~ gpaq8totmin + gpaq11days + bmi + povertygroup + agegroup, data = class4, method = "glm", family = "gaussian", trControl = control.settings)

model2_pred <- predict(model2_again, class4_test)

model2_again

postResample(pred = model2_pred, obs = class4_test$healthydays)
```
My first model includes 3 variables: BMI, gpaq8totmin(minutes of total physical activity on home chores on an average day) and gpaq11days (during the last 7 days, on how many days did you walk to get to and from places?). The root mean square error was 7.654. After running the postResample, my RSME became 7.800.

My second model includes these three variables plus poverty group (is your household’s annual income from all source: 1 = <100%, 2 = 100-199%, 3 = 200-399%, 4 = 400-599%, 5 = 600%, 6 = Don’t know) and agegroup (group 1 = 18-24, group 2 = 25-44, group 3 = 45-64, and group 4 = 65+). The root mean square error was 7.444. After running the postResample, my RSME became 7.502.

Since the Mean Square Error (RMSE) is a standard way to measure the error in our model, the larger the number the larger the error. I would recommend the second model which included 5 variables as the preferred prediction model because it had a slightly lower RMSE. 

#Question 3
```{r}
#Q3 Task: Describe one setting (in 1-2 sentences) where the implementation of your final model would be useful.

My final model may be useful in a low-income community where there may be lack of access to 

```

## Part II: Conducting an Unsupervised Analysis
Using the dataset from the Group assignment Part 3 (USArrests), identify clusters using hierarchical analysis. Use an agglomerative algorithm for hierarchical clustering. Use a Euclidian distance measure to construct your dissimilarity matrix.

#Question 4
```{r}
#Q4 Task: Conduct a hierarchical clustering analysis. Be sure to specify the linkage method used. Within your analysis, make sure you do both of the following:
#  1. Determine the optimal number of clusters using a clear, data-driven strategy.
#  2. Describe the composition of each cluster in terms of the original input features

data(USArrests)
#Check means and SDs to determine if scaling is necessary
colMeans(USArrests, na.rm = TRUE)
apply(USArrests, 2, sd, na.rm = TRUE)

# NTS: First I need to create Dissimilarity matrix
diss_matrix <- dist(USArrests, method = "euclidean")

#NTS: Then hierarchical clustering using Complete Linkage
clusters_h <- hclust(diss_matrix, method = "complete" )

# Plot the obtained dendrogram
plot(clusters_h, cex = 0.4, hang = -1)

#NTS: Now I need to choose where to cut across my dendrogram to choose my number of clusters. In order to do that I have to  creating a function to use within clusGap. I am now using an average linkage. After running the function, I will plot the gapstat to visualize it

hclusCut <- function(x, k) list(cluster = cutree(hclust(dist(x, method = "euclidian"), method ="average"), k = k))

gap_stat <- clusGap(USArrests, FUN = hclusCut, K.max = 10, B = 50)
fviz_gap_stat(gap_stat)

#NTS: Now, use the number of clusters from gap statistic to obtain cluster assignment for each observation
clusters_h3 <- cutree(clusters_h, k = 3)
table(clusters_h3)

#Now I want to take those values and put it back onto my original dataset
input_feature_values <- cbind(USArrests,cluster = clusters_h$cluster) 

input_feature_values %>%
  group_by(cluster) %>%
  summarise_all(mean)

```
Q4 Answers: I used Euclidean as my distance metric and complete linkage so that I can use the distance between all of the different data points. After visualizing the gapstat, the optimal number of clusters was 3. 

```{r}
#Question 5: Pretend that the data are from 2020 and not 1973. Describe one research question that can be addressed using the newly identified clusters. Briefly comment on any scientific or ethical considerations one should review before using these clusters for your specific question. NOTE: The clusters can be used as an exposure, an outcome or a covariate.
```

